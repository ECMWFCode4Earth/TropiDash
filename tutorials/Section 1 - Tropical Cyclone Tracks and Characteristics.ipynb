{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tropical Cyclone Tracks and Characteristics Notebook Tutorial\n",
    "\n",
    "This tutorial aims at giving a better idea abouth the operations streamflow behind the visualization of data in the first section of **TropiDash**. This section focuses on displaying information regarding the cyclone tracks and their spatial characteristics. More in particular the data available for consultation are:\n",
    "\n",
    "1. Ensemble tracks forecast of the cyclone\n",
    "2. Average forecast track of the cyclone \n",
    "3. Observed track of the cyclone\n",
    "4. Strike Probability Map\n",
    "\n",
    "As example for the tutorial we adopted the forecast of cyclone **LEE** on **September 7, 2023**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdbufr\n",
    "import math\n",
    "import ipyleaflet\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import branca.colormap as bc\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from localtileserver import get_leaflet_tile_layer, TileClient\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Donwload\n",
    "\n",
    "Since this is a tutorial, the cell below is is a raw cell instead of a code cell. The data have been already downloaded and you do not need to run it. As source of data for the forecast we use ECMWF open dataset, for the observed track we use __[IBTrACS](https://www.ncei.noaa.gov/products/international-best-track-archive)__.\n",
    "\n",
    "Be aware that the code reported donwloads the latest data availabe for active cyclones from IBTrACS. If you run it it will overwrite the .csv file containing information about LEE that were availabe on the 7th September 2023. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define the starting date of the forecast (7th September 2023)\n",
    "start_date = datetime(2023, 9, 7, 0, 0)\n",
    "\n",
    "# Define the ECMWF server source of data\n",
    "client = Client(source=\"azure\")\n",
    "\n",
    "# Download the data from the ECMWF server\n",
    "client.retrieve(\n",
    "    date=int(start_date.strftime(\"%Y%m%d\")),\n",
    "    time=0,\n",
    "    stream=\"enfo\",\n",
    "    type=\"tf\",\n",
    "    step=240,\n",
    "    target=f\"data/tracks/{start_date.strftime('%Y%m%d')}.bufr\",\n",
    ");\n",
    "\n",
    "# Open request to acces and download IBTrACS data\n",
    "url = 'https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/csv/ibtracs.ACTIVE.list.v04r00.csv'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "# Save request content to file\n",
    "with open('data/tracks/ibtracs.ACTIVE.list.v04r00.csv', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Load and Pre-formatting\n",
    "\n",
    "The forecast tracks data of ECMWF are in .bufr format to load them as a pandas dataframe we use the bufr library.\n",
    "\n",
    "For the way the file are built is not possible to load together the column of the mean sea level pressure at the core of the cyclone and the column of the maximum wind speed at 10 meters within the cyclone system. Two different dataframes are created and then merged together. Also, in the original file the column of temporal information, i.e. the hours after the forecast date, might contain erros so we manually computed it and insert it in the dataframe. At last we remove all cyclones having identifier smaller than 70 since they do not represent real events and we select the cyclone we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2023, 9, 7, 0, 0)\n",
    "\n",
    "# Load cyclone dataframe with Mean sea level pressure value\n",
    "df_storms_forecast = pdbufr.read_bufr(f\"data/tracks/{start_date.strftime('%Y%m%d')}.bufr\",\n",
    "    columns=(\"stormIdentifier\", \"longStormName\", \"ensembleMemberNumber\", \"year\", \"month\", \"day\", \"hour\", \"latitude\", \"longitude\", \n",
    "             \"pressureReducedToMeanSeaLevel\"))\n",
    "\n",
    "# Load cyclone dataframe with Wind speed at 10m value\n",
    "df1 = pdbufr.read_bufr(f\"data/tracks/{start_date.strftime('%Y%m%d')}.bufr\",\n",
    "    columns=(\"stormIdentifier\", \"longStormName\", \"ensembleMemberNumber\", \"latitude\", \"longitude\",\n",
    "                \"windSpeedAt10M\"))\n",
    "\n",
    "# Build the timeperiod column for the dataframe\n",
    "timeperiod = []\n",
    "start_date = datetime(df_storms_forecast.year[0], df_storms_forecast.month[0], df_storms_forecast.day[0], df_storms_forecast.hour[0])\n",
    "for cyclone in df_storms_forecast.stormIdentifier.unique():\n",
    "    df_cyclone = df_storms_forecast[df_storms_forecast.stormIdentifier == cyclone]\n",
    "    df_cyclone.reset_index(inplace=True, drop=True)\n",
    "    members = df_cyclone.ensembleMemberNumber.unique()\n",
    "    for member in members:\n",
    "        df_track = df_cyclone[df_cyclone.ensembleMemberNumber == member]\n",
    "        for i in range(len(df_track)):\n",
    "            timeperiod.append(6 * (i+1))\n",
    "\n",
    "# Add the Wind speed at 10m column adn the timePeriod column to the storms dataframe \n",
    "df_storms_forecast[\"windSpeedAt10M\"] = df1.windSpeedAt10M\n",
    "df_storms_forecast[\"timePeriod\"] = timeperiod\n",
    "del df1\n",
    "\n",
    "# Storms with stormIdentifier higher than 70 are not real storms\n",
    "drop_condition = df_storms_forecast.stormIdentifier < '70'\n",
    "df_storms_forecast = df_storms_forecast[drop_condition]\n",
    "\n",
    "# Select the data of storm LEE (Storm Identifier: 13L)\n",
    "df_storm_forecast = df_storms_forecast[df_storms_forecast.stormIdentifier == '13L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observed data\n",
    "df_storms_observed = pd.read_csv('data/tracks/ibtracs.ACTIVE.list.v04r00.csv', header=[0,1])\n",
    "\n",
    "# Select the data of storm LEE\n",
    "df_storm_observed = df_storms_observed[df_storms_observed.NAME.squeeze() == 'LEE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracks Location Computation\n",
    "\n",
    "To plot the tracks in an interactive map we use the python library **ipyleaflet**. This library requires to have the locations saved in a list to represent plot them as polylines on a map. The following code converts the different tracks locations from a dataframe column to a list of locations lists in case of the ensemble tracks and to a locations list in case of the observed track. \n",
    "\n",
    "The average forecast track is also computed using the appropriate trigonometric formula. \n",
    "\n",
    "For each track we also compute the list of time steps, mean sea level pressure and wind speed for the correspondent location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Forecast Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Members to Plot Widget\n",
    "This widget allows you to decide which ensembles you want to plot in the Map. Since several polylines in the Map makes it unstable, if you select more than 5 ensemble members it will not report all the rest of the information mentioned before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9557b768d8704ceeba05278b42c1c2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='Multiple values can be selected with <b>shift</b> and/or <b>ctrl</b> (or <b>command</b>)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fbb6cc571c4afcb8ac1c0385c033af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Ensemble members to plot:', options=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the widget to select which ensemble members to plot\n",
    "members = df_storm_forecast.ensembleMemberNumber.unique()\n",
    "ens_members = widgets.SelectMultiple(\n",
    "    options=members,\n",
    "    value=[],\n",
    "    description=\"Ensemble members to plot:\",\n",
    "    disable=False\n",
    ")\n",
    "\n",
    "ens_members.style.description_width = '168px'\n",
    "ens_members.style.font_weight = 'bold'\n",
    "\n",
    "# Widget for instruction on how to select the ensemble members to plot\n",
    "message_ens = widgets.HTML(\n",
    "    value=\"Multiple values can be selected with <b>shift</b> and/or <b>ctrl</b> (or <b>command</b>)\",\n",
    ")\n",
    "\n",
    "display(message_ens)\n",
    "display(ens_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the tracks in the forecast dataframe according to the ensemble mebers seleced by user\n",
    "df_f = df_storm_forecast[df_storm_forecast.ensembleMemberNumber.isin(ens_members)]\n",
    "df_f.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# List all the ensemble members tracks for the cyclone forecast and define the empty lists\n",
    "members = df_f.ensembleMemberNumber.unique()\n",
    "locations_f = []\n",
    "timesteps_f = []\n",
    "pressures_f = []\n",
    "wind_speeds_f = []\n",
    "\n",
    "# Cycle through the members of the forecast\n",
    "for member in members:\n",
    "    df_track = df_f[df_f.ensembleMemberNumber == member]\n",
    "    df_track.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a date column in dataframe\n",
    "    start = datetime(df_track.iloc[0]['year'], df_track.iloc[0]['month'], df_track.iloc[0]['day'], df_track.iloc[0]['hour'])\n",
    "    df_track['date'] = start + timedelta(hours=6) * (df_track.index+1)\n",
    "    df_track.dropna(subset = ['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "    # Save the information from a single track in lists\n",
    "    latitude = df_track.latitude.tolist()\n",
    "    longitude = df_track.longitude.tolist()\n",
    "    dates = df_track.date.tolist()\n",
    "    pressure = df_track.pressureReducedToMeanSeaLevel.tolist()\n",
    "    wind_speed = df_track.windSpeedAt10M.tolist()\n",
    "    locs = []\n",
    "    tmtstps = []\n",
    "    press = []\n",
    "\n",
    "    # Cycle through the list of location\n",
    "    for i in range(len(latitude)):\n",
    "        loc = (latitude[i], longitude[i])\n",
    "        locs.append(loc)\n",
    "        tmtstps.append(dates[i].strftime(\"%d-%m-%Y %H:%M\"))\n",
    "        press.append(pressure[i] * 10**-2) # Pa to hPa\n",
    "\n",
    "    locations_f.append(locs)\n",
    "    timesteps_f.append(tmtstps)\n",
    "    pressures_f.append(press)\n",
    "    wind_speeds_f.append(wind_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe columns to lists\n",
    "latitude = df_storm_observed.LAT.squeeze().tolist()\n",
    "longitude = df_storm_observed.LON.squeeze().tolist()\n",
    "dates = df_storm_observed.ISO_TIME.squeeze().tolist()\n",
    "locations_o = []\n",
    "timesteps_o = []\n",
    "\n",
    "# Cycle through the lists\n",
    "for i in range(len(latitude)):\n",
    "    loc = (latitude[i], longitude[i])\n",
    "    date = datetime.strptime(dates[i][:-3], ('%Y-%m-%d %H:%M'))\n",
    "    locations_o.append(loc)\n",
    "    timesteps_o.append(date.strftime('%d-%m-%Y %H:%M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Forecast Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanposit(knpf, rlatpf, rlonpf):\n",
    "    \"\"\"\n",
    "    Computes the average coordinates from the ensemble tracks at a specific timestep.\n",
    "    \n",
    "    knpf: int\n",
    "        Number of ensemble tracks \n",
    "    rlatpf: numpy array\n",
    "        Array containing the latitudes of the ensemble tracks\n",
    "    rlonpf: numpy array\n",
    "        Array containing the longitudes of the ensemble tracks\n",
    "    \n",
    "    Returns:\n",
    "    rlatmean: float\n",
    "        Mean latitude at the timestep\n",
    "    rlonmean: float\n",
    "        Mean longitude at the timestep\n",
    "    \"\"\"\n",
    "    rpi = math.acos(0.0)\n",
    "    rnomin = 0.0\n",
    "    rdenom = 0.0\n",
    "    rphisum = 0.0\n",
    "    \n",
    "    for k in range(knpf):\n",
    "        rlat = rlatpf[k] * rpi / 180.0\n",
    "        rlon = rlonpf[k] * rpi / 180.0\n",
    "        rcosphi = math.cos(rlat)\n",
    "        rnomin += rcosphi * rlon\n",
    "        rdenom += rcosphi\n",
    "        rphisum += rlat\n",
    "    \n",
    "    rlabda = rnomin / rdenom\n",
    "    rlonmean = rlabda * 180.0 / rpi\n",
    "    \n",
    "    rnomin = 0.0\n",
    "    repsilon = 0.0\n",
    "    \n",
    "    for k in range(knpf):\n",
    "        rlat = rlatpf[k] * rpi / 180.0\n",
    "        rlon = rlonpf[k] * rpi / 180.0\n",
    "        rcosphi = math.cos(rlat)\n",
    "        rnomin += rcosphi * (rlabda - rlon) ** 2\n",
    "    \n",
    "    repsilon = rnomin / (2.0 * knpf)\n",
    "    rphimean = rphisum / float(knpf)\n",
    "    rphi = rphimean + repsilon * math.sin(rphimean)\n",
    "    rlatmean = rphi * 180.0 / rpi\n",
    "    \n",
    "    return rlatmean, rlonmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframes to fill with each ensemble members information\n",
    "members = df_storm_forecast.ensembleMemberNumber.unique()\n",
    "df_lat_tracks = pd.DataFrame()\n",
    "df_lon_tracks = pd.DataFrame()\n",
    "df_prs_tracks = pd.DataFrame()\n",
    "df_wds_tracks = pd.DataFrame()\n",
    "\n",
    "# Cycle thorugh the ensemble members and save the information in the just created dataframes\n",
    "for member in members:\n",
    "    df_track = df_storm_forecast[df_storm_forecast.ensembleMemberNumber == member]\n",
    "    df_track.reset_index(drop=True, inplace=True)\n",
    "    df_lat_tracks[f'latitude{member}'] = df_track.latitude\n",
    "    df_lon_tracks[f'longitude{member}'] = df_track.longitude\n",
    "    df_prs_tracks[f'pressure{member}'] = df_track.pressureReducedToMeanSeaLevel\n",
    "    df_wds_tracks[f'wind{member}'] = df_track.windSpeedAt10M\n",
    "\n",
    "# Add date information for the average track\n",
    "df_track.reset_index(drop=True, inplace=True)\n",
    "start = datetime(df_track.iloc[0]['year'], df_track.iloc[0]['month'], df_track.iloc[0]['day'], df_track.iloc[0]['hour'])\n",
    "dates = start + timedelta(hours=6) * (df_track.index+1)\n",
    "\n",
    "# Cycle through the rows of df_lat_track and df_lon_tracks to compute the average track lat,lon and pressure and wind speed perecentiles\n",
    "locations_avg = []\n",
    "timesteps_avg = []\n",
    "pressures_avg = []\n",
    "wind_speeds_avg = []\n",
    "\n",
    "for t in range(len(df_lat_tracks)):\n",
    "    lat = df_lat_tracks.iloc[t].dropna().to_numpy()\n",
    "    lon = df_lon_tracks.iloc[t].dropna().to_numpy()\n",
    "    prs = df_prs_tracks.iloc[t].dropna().to_numpy()  * 10**-2 # Pa to hPa\n",
    "    wds = df_wds_tracks.iloc[t].dropna().to_numpy()\n",
    "    date = dates[t].strftime(\"%d-%m-%Y %H:%M\")\n",
    "    if len(lat) > 0:\n",
    "        mean_lat_lon = meanposit(len(lat), lat, lon)\n",
    "        pressures_avg.append(np.percentile(prs, [10, 25, 50, 75, 90]))\n",
    "        wind_speeds_avg.append(np.percentile(wds, [10, 25, 50, 75, 90]))\n",
    "        locations_avg.append(mean_lat_lon)\n",
    "        timesteps_avg.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strike Probability Map Computation\n",
    "\n",
    "The strike probability is the probbaility that a tropical cyclone will pass within a 300 km radius from a given location and within a time window of 48 hours. This information provides a quick assessment of high-risk areas. If you want to know more about check the following  __[link](https://charts.ecmwf.int/products/medium-tc-genesis?base_time=202309140000&layer_name=genesis_ts&projection=opencharts_global&valid_time=202309170000)__.\n",
    "\n",
    "The strike probability map is computed through a series of operations relying on the construction of a space-partitioning data structure called *k*-d tree. Since the code to compute the strike probbaility map is quite long, we preffered to not report it here in the tutorial notebook. If you are interesed in the computation of the strike probability map you can chek out the python script *strike_map.py*. \n",
    "\n",
    "The strike probability map is saved to a raster file to visualize it in the ipyleaflet map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strike_map import strike_probability_map\n",
    "\n",
    "# Compute the strike probability map and save it to raster file\n",
    "df_storm = df_storm_forecast.copy()\n",
    "strike_map_xr, tif_path = strike_probability_map(df_storm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data in an Interactive Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Ensemble Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colours list for the ensemble tracks\n",
    "colours = [\"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"orange\", \"cyan\", \"brown\"]\n",
    "tracks_layer = []\n",
    "colour = 0\n",
    "i = 0\n",
    "\n",
    "# Cycle on the ensembles of the forecast track\n",
    "for locs in locations_f:\n",
    "\n",
    "    tmtstps = timesteps_f[i]\n",
    "    press = pressures_f[i]\n",
    "    wind = wind_speeds_f[i]\n",
    "    \n",
    "    # Define the ensemble track polyline for the map\n",
    "    track = ipyleaflet.Polyline(\n",
    "        locations=locs,\n",
    "        color=colours[colour],\n",
    "        fill=False,\n",
    "        weight=2,\n",
    "    )\n",
    "\n",
    "    # If the number of ensemble members is less than 5, define the markers for each position of the cyclone ensemble forecast\n",
    "    if len(locations_f) <= 5:\n",
    "        markers = []\n",
    "        for j in range(len(locs)):\n",
    "            marker = ipyleaflet.CircleMarker(\n",
    "                location=locs[j],\n",
    "                radius=1,\n",
    "                color=colours[colour],\n",
    "                popup=widgets.HTML(value=f'<center><b>{tmtstps[j]}</b> <br> Pressure: {press[j]:.2f} hPa <br> Wind speed: {wind[j]:.2f} m/s</center>')\n",
    "            )\n",
    "            markers.append(marker)\n",
    "        markers_layer = ipyleaflet.LayerGroup(layers=markers)\n",
    "        track_layer = ipyleaflet.LayerGroup(layers=[track, markers_layer])\n",
    "        tracks_layer.append(track_layer)\n",
    "    else:\n",
    "        tracks_layer.append(track)\n",
    "        \n",
    "    colour += 1\n",
    "    if colour == len(colours):\n",
    "        colour = 0\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Forecast Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define average forecast track polyline for the map\n",
    "track_avg = ipyleaflet.Polyline(\n",
    "        locations=locations_avg,\n",
    "        color=\"black\",\n",
    "        fill=False,\n",
    "        weight=3,\n",
    "    )\n",
    "\n",
    "# Define the markers element for each position of the average track\n",
    "marker_avg = []\n",
    "for avg in range(len(locations_avg)):\n",
    "    marker = ipyleaflet.CircleMarker(\n",
    "        location = locations_avg[avg],\n",
    "        radius=1,\n",
    "        color=\"black\",\n",
    "        popup=widgets.HTML(value=f\"<center><b> {timesteps_avg[avg]} </b> </center>\"\n",
    "                            f\"Percentiles: Pressure || Wind speed <br>\"\n",
    "                            f\"10-th: {pressures_avg[avg][0]:.1f} hPa || {wind_speeds_avg[avg][0]:.2f} m/s <br>\"\n",
    "                            f\"25-th: {pressures_avg[avg][1]:.1f} hPa || {wind_speeds_avg[avg][1]:.2f} m/s <br>\"\n",
    "                            f\"50-th: {pressures_avg[avg][2]:.1f} hPa || {wind_speeds_avg[avg][2]:.2f} m/s <br>\"\n",
    "                            f\"75-th: {pressures_avg[avg][3]:.1f} hPa || {wind_speeds_avg[avg][3]:.2f} m/s <br>\"\n",
    "                            f\"90-th: {pressures_avg[avg][4]:.1f} hPa || {wind_speeds_avg[avg][4]:.2f} m/s\"\n",
    "                            )\n",
    "    )\n",
    "    marker_avg.append(marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define observed tracks polyline element for the map\n",
    "track_o = ipyleaflet.Polyline(\n",
    "        locations=locations_o,\n",
    "        color= \"#ff00ff\",\n",
    "        fill=False,\n",
    "        weight=2,\n",
    "    )\n",
    "\n",
    "# Define the markers element for each position of the observed track\n",
    "marker_o = []\n",
    "for o in range(len(locations_o)):\n",
    "    marker = ipyleaflet.CircleMarker(\n",
    "        location = locations_o[o],\n",
    "        radius=1,\n",
    "        color=\"#ff00ff\",\n",
    "        popup=widgets.HTML(value=f'<b> {timesteps_o[o]} </b>')\n",
    "    )\n",
    "    marker_o.append(marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strike Probability Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster file and define layer for strike probability map\n",
    "client = TileClient(tif_path)\n",
    "palette = [\"#8df52c\", \"#6ae24c\", \"#61bb30\", \"#508b15\", \"#057941\", \"#2397d1\", \"#557ff3\", \"#143cdc\", \"#3910b4\", \"#1e0063\"]\n",
    "stp_map = get_leaflet_tile_layer(client, name = \"Strike Probability Map\", opacity = 0.8, palette = palette, nodata=0.0)\n",
    "\n",
    "# Define colormap for the strike probability map\n",
    "with rasterio.open(tif_path) as r:\n",
    "    minv = \"%.2f\" % round(r.read(1).ravel().min(), 1)\n",
    "    maxv = \"%.2f\" % round(r.read(1).ravel().max(), 1)\n",
    "\n",
    "cmap_control = ipyleaflet.ColormapControl(\n",
    "                            caption = \"Strike probability\",\n",
    "                            colormap = bc.StepColormap(palette),\n",
    "                            value_min = float(minv),\n",
    "                            value_max = float(maxv),\n",
    "                            position = 'topright',\n",
    "                            transparent_bg = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map and Layers Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the map\n",
    "initial_lat_lon = (df_storm_forecast.latitude.iloc[0], df_storm_forecast.longitude.iloc[0])\n",
    "tc_track_map = ipyleaflet.Map(\n",
    "        center=initial_lat_lon,\n",
    "        basemap=ipyleaflet.basemaps.OpenStreetMap.France,\n",
    "        zoom = 3.0,\n",
    "        # scroll_wheel_zoom=True,\n",
    "    )\n",
    "\n",
    "# Add the observed track layer to the map \n",
    "markers_layer_o = ipyleaflet.LayerGroup(layers=marker_o)\n",
    "layer_group_o = ipyleaflet.LayerGroup(layers=[track_o, markers_layer_o], name='Observed Track')\n",
    "tc_track_map.add_layer(layer_group_o)\n",
    "\n",
    "# Add the ensemble tracks layer to the map\n",
    "tracks_layer_group = ipyleaflet.LayerGroup(layers=tracks_layer, name='Forecasted Ensemble Tracks')\n",
    "tc_track_map.add_layer(tracks_layer_group)\n",
    "\n",
    "# Add the average forecast track layer to the map\n",
    "markers_layer_avg = ipyleaflet.LayerGroup(layers=marker_avg)\n",
    "layer_group_avg = ipyleaflet.LayerGroup(layers=[track_avg, markers_layer_avg], name='Average Forecast Track')\n",
    "tc_track_map.add_layer(layer_group_avg)\n",
    "\n",
    "# Add the strike probability map layer to the map\n",
    "tc_track_map.add_layer(stp_map)\n",
    "tc_track_map.add_control(cmap_control)\n",
    "\n",
    "# Add layers widget to the map\n",
    "layers_control = ipyleaflet.LayersControl()\n",
    "tc_track_map.add_control(layers_control)\n",
    "tc_track_map.add_control(ipyleaflet.FullScreenControl());\n",
    "\n",
    "# Display the map\n",
    "display(tc_track_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TropiDash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
